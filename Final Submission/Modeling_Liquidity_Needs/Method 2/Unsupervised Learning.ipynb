{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train_shock = pd.read_csv('ss_train_shock.csv')\n",
    "ss_test_shock = pd.read_csv('ss_test_shock.csv')\n",
    "ss_train_shock = ss_train_shock.dropna()\n",
    "ss_test_shock = ss_test_shock.dropna()\n",
    "ss_train_shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e04a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train_shock.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074501ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ss_train_shock.drop(ss_train_shock.columns[0], axis=1)\n",
    "X_train = train.drop(['percent_increase','WEIGHT','HHIDPN','percent_increase','LAST_YEAR', 'SPEND_SS','SHOCK2'], axis=1)\n",
    "y_train = train['SHOCK2']\n",
    "other_train = ss_train_shock[['percent_increase','WEIGHT','percent_increase','LAST_YEAR', 'SPEND_SS','SHOCK2','HHIDPN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ss_test_shock.drop(ss_test_shock.columns[0], axis=1)\n",
    "X_test = test.drop(['percent_increase','WEIGHT','HHIDPN','percent_increase','LAST_YEAR', 'SPEND_SS','SHOCK2'], axis=1)\n",
    "y_test = test['SHOCK2']\n",
    "other_test = ss_test_shock[['percent_increase','WEIGHT','percent_increase','LAST_YEAR', 'SPEND_SS','SHOCK2','HHIDPN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2efbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d324d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca033af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.concat([X_train,X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec00ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "X = X_train_norm\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "samples_norm = scaler.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e18c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "random_state = 42\n",
    "prp_var = [50,200,300,400,500,600,700]\n",
    "for i in prp_var:\n",
    "    tsne = TSNE(n_components=2, init='random', random_state=random_state, perplexity=i,n_jobs=-1)\n",
    "    X_proj = tsne.fit_transform(samples_norm)\n",
    "    X_test_tsne = X_proj[-16260:]\n",
    "    X_train_tsne = X_proj[:37772]\n",
    "    print(X_test_tsne.shape)\n",
    "    print(X_train_tsne.shape)\n",
    "    X_proj = X_train_tsne\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], \\\n",
    "            c=[cm.Spectral(float(i)*3 / 8) for i in y_train])\n",
    "    plt.title(\"t-SNE transformed data \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bb466",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prp_var = [800,1000,1200,1400,1600,1800]\n",
    "for i in prp_var:\n",
    "    tsne = TSNE(n_components=2, init='random', random_state=random_state, perplexity=i,n_jobs=-1)\n",
    "    X_proj = tsne.fit_transform(samples_norm)\n",
    "    X_test_tsne = X_proj[-16260:]\n",
    "    X_train_tsne = X_proj[:37772]\n",
    "    print(X_test_tsne.shape)\n",
    "    print(X_train_tsne.shape)\n",
    "    X_proj = X_train_tsne\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], \\\n",
    "            c=[cm.Spectral(float(i)*3 / 8) for i in y_train])\n",
    "    plt.title(\"t-SNE transformed data \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833f14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prp_var = [2000,2400,2800]\n",
    "random_state = 42\n",
    "for i in prp_var:\n",
    "    tsne = TSNE(n_components=2, init='random', random_state=random_state, perplexity=i,n_jobs=-1)\n",
    "    X_proj = tsne.fit_transform(samples_norm)\n",
    "    X_test_tsne = X_proj[-16260:]\n",
    "    X_train_tsne = X_proj[:37772]\n",
    "    print(X_test_tsne.shape)\n",
    "    print(X_train_tsne.shape)\n",
    "    X_proj = X_train_tsne\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], \\\n",
    "            c=[cm.Spectral(float(i)*3 / 8) for i in y_train])\n",
    "    plt.title(\"t-SNE transformed data \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "random_state = 42\n",
    "prp_var = 1800\n",
    "\n",
    "# # Transform  dimensional data to 2 dimensions\n",
    "tsne = TSNE(n_components=2, init='random', random_state=random_state, perplexity=prp_var,n_jobs=-1)\n",
    "X_proj = tsne.fit_transform(samples_norm)\n",
    "X_test_tsne = X_proj[-16260:]\n",
    "X_train_tsne = X_proj[:37772]\n",
    "print(X_test_tsne.shape)\n",
    "print(X_train_tsne.shape)\n",
    "X_proj = X_train_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], \\\n",
    "            c=[cm.Spectral(float(i)*3 / 8) for i in y_train])\n",
    "plt.title(\"t-SNE Transformed Data, Perplexity = 1800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e679e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps_values = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "for eps in eps_values:\n",
    "    dbs = DBSCAN(eps=eps)\n",
    "    clusters = dbs.fit_predict(X_proj)\n",
    "\n",
    "    # Calculate the unique clusters and their counts\n",
    "    uq = np.unique(clusters)\n",
    "    num_clusters = len(uq)\n",
    "\n",
    "    # Permute the labels based on the mode of the original labels\n",
    "    labels = np.zeros_like(clusters)\n",
    "    for i in uq:  # Change range(10) to unique values in clusters to handle varying cluster numbers\n",
    "        mask = (clusters == i)\n",
    "        # Only assign a label if there are any points in the cluster\n",
    "        if np.any(mask):\n",
    "            labels[mask] = mode(y_train[mask])[0][0]\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(X_proj[:, 0], X_proj[:, 1], c=[cm.Spectral(float(i) / num_clusters) for i in clusters])\n",
    "    plt.title(f\"t-SNE transformed data with EPS = {eps}\")\n",
    "    \n",
    "    # Calculate and annotate cluster centers\n",
    "    centers = {}\n",
    "    for i in uq:\n",
    "        if i != -1:  # Skip noise points\n",
    "            center = X_proj[clusters == i].mean(axis=0)\n",
    "            centers[i] = center\n",
    "            plt.text(center[0], center[1], str(i), ha=\"center\", va=\"center\", size=15,\n",
    "                     bbox=dict(boxstyle=\"circle,pad=0.1\", fc=\"lightblue\", ec=\"steelblue\", lw=2))\n",
    "    \n",
    "    plt.show()  # Show the plot for each value of eps\n",
    "\n",
    "    # Print the number of clusters\n",
    "    print(f\"Number of clusters for eps={eps}: {num_clusters}\")\n",
    "\n",
    "    # Compute and print the F1 score\n",
    "    f1 = f1_score(y_train, labels, average='micro')\n",
    "    print(f\"F1 Score for eps={eps}: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 7\n",
    "\n",
    "dbs = DBSCAN(eps = eps)\n",
    "\n",
    "#X_proj = TSNE_DONE[perp][:8000]\n",
    "clusters = dbs.fit_predict(X_proj)\n",
    "\n",
    "uq = np.unique(clusters)\n",
    "num_clusters = len(uq)\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(kmeans.cluster_centers_[:, 0], sc.cluster_centers_[:, 1], s=300, c='black')\n",
    "\n",
    "\n",
    "# Permute the labels\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y_train[mask])[0]\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_proj[:, 0], X_proj[:, 1], \\\n",
    "          c=[cm.Spectral(float(i) / num_clusters) for i in clusters])\n",
    "plt.title(\"t-SNE Transformed Data for EPS = \" + str(eps))\n",
    "centers = {}\n",
    "counts = {}\n",
    "for i in uq:\n",
    "    count = 0\n",
    "    center = np.zeros(2)\n",
    "    for c in range(0, len(clusters)):\n",
    "        if (clusters[c] != i):\n",
    "            continue\n",
    "        count = count + 1\n",
    "        center = center + X_proj[c]\n",
    "    if (count > 0):\n",
    "        counts[i] = count\n",
    "        centers[i] = center / count\n",
    "\n",
    "print(num_clusters)\n",
    "\n",
    "for i in centers.keys():\n",
    "    if i > 25:\n",
    "        break\n",
    "    loc = centers[i]\n",
    "    plt.text(loc[0], loc[1], str(i), ha=\"center\", va=\"center\", size=15,\n",
    "            bbox=dict(boxstyle=\"circle,pad=0.1\",\n",
    "                      fc=\"lightblue\", ec=\"steelblue\", lw=2))\n",
    "  #plt.show()\n",
    "# Compute the accuracy\n",
    "f1_score(y_train, labels, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e499482",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = np.unique(clusters)\n",
    "\n",
    "\n",
    "clu_defect = {i: 0 for i in unique_clusters}\n",
    "clu_total = {i: 0 for i in unique_clusters}\n",
    "\n",
    "\n",
    "for i, cluster_id in enumerate(clusters):\n",
    "    if y_train[i]:  \n",
    "        clu_defect[cluster_id] += 1\n",
    "    clu_total[cluster_id] += 1\n",
    "\n",
    "print(clu_total)\n",
    "print(clu_defect)\n",
    "\n",
    "# Calculate and print defect percentage for each actual cluster (excluding noise)\n",
    "for i in unique_clusters:\n",
    "    if i != -1:  # Skip noise\n",
    "        total = clu_total[i]\n",
    "        defect = clu_defect[i]\n",
    "        defect_percentage = defect / total if total > 0 else 0 \n",
    "        print(f\"{i}th cluster has a total of {total} and a {defect_percentage:.2%} percentage to experience wealth shock\")\n",
    "\n",
    "\n",
    "clu_defect_perc = {i: (clu_defect[i] / clu_total[i] if clu_total[i] > 0 else 0) for i in unique_clusters if i != -1}\n",
    "for i in sorted(clu_defect_perc.keys(), key=clu_defect_perc.get):\n",
    "    print(f\"{i}: {clu_defect_perc[i]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(y_train)/37772)\n",
    "print(sum(y_test)/16260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93699083",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clusters = []\n",
    "\n",
    "#X_test_tsne = TSNE_DONE[perp][-2000:]\n",
    "\n",
    "for i in X_test_tsne:\n",
    "    min = np.linalg.norm(X_train_tsne[0] - i)\n",
    "    value = 0\n",
    "    for j in range(0,len(X_train_tsne)):\n",
    "        if np.linalg.norm(X_train_tsne[j] - i) >= min:\n",
    "            continue\n",
    "        min = np.linalg.norm(X_train_tsne[j] - i)\n",
    "        value = j\n",
    "    test_clusters.append(clusters[value])\n",
    "test_clusters = np.array(test_clusters)\n",
    "\n",
    "plt.scatter(X_test_tsne[:, 0], X_test_tsne[:, 1], \\\n",
    "          c=[cm.Spectral(float(i) / num_clusters) for i in test_clusters])\n",
    "for i in centers.keys():\n",
    "    if i > 25:\n",
    "        break\n",
    "    loc = centers[i]\n",
    "    plt.text(loc[0], loc[1], str(i), ha=\"center\", va=\"center\", size=15,\n",
    "            bbox=dict(boxstyle=\"circle,pad=0.1\",\n",
    "                      fc=\"lightblue\", ec=\"steelblue\", lw=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12734bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_train.reset_index(drop=True, inplace=True)\n",
    "other_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73145fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clusters = X_train.copy()\n",
    "X_train_clusters[\"cluster\"] = clusters\n",
    "Shock_train_clusters = pd.concat([X_train_clusters, y_train, other_train], axis=1)\n",
    "Shock_train_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clusters = X_test.copy()\n",
    "X_test_clusters[\"cluster\"] = test_clusters\n",
    "Shock_test_clusters = pd.concat([X_test_clusters, y_test, other_test], axis=1)\n",
    "Shock_test_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23877dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_test_defect = {i:0 for i in range(0,num_clusters)}\n",
    "clu_test_total = {i:0 for i in range(0,num_clusters)}\n",
    "for i in range(0,len(test_clusters)):\n",
    "    if y_test[i]:\n",
    "        clu_test_defect[test_clusters[i]] += 1\n",
    "    clu_test_total[test_clusters[i]] += 1\n",
    "\n",
    "print(clu_test_total)\n",
    "print(clu_test_defect)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"{:d}th cluster is: \".format(i))\n",
    "    print(X_test.iloc[i])\n",
    "    print(\"And has a total of {:d} and a {:f} chance to experience wealth shock\".format(clu_test_total[i],clu_test_defect[i]/clu_test_total[i]))\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "clu_test_defect_perc = {i:(clu_test_defect[i]/clu_test_total[i]) for i in range(0,num_clusters)}\n",
    "for i in (sorted(clu_test_defect_perc.keys(), key=clu_test_defect_perc.get)):\n",
    "    print(\"{:d}: {:f}\".format(i, clu_test_defect_perc[i]))\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "for i in clu_test_defect_perc.keys():\n",
    "    print(\"{:d}: {:f}\".format(i, clu_defect_perc[i] - clu_test_defect_perc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ac0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_train_data = []\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    c_train_data.append(Shock_train_clusters[Shock_train_clusters[\"cluster\"] == i].drop(\"cluster\",axis=1))\n",
    "\n",
    "for i in range(len(c_train_data)):\n",
    "    print(\"CLUSTER {:d}\".format(i))\n",
    "    display(c_train_data[i])\n",
    "    print(\"-\" * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "columns = c_train_data[0].columns\n",
    "\n",
    "for col in columns:\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for i, df in enumerate(c_train_data):\n",
    "        temp_df = df[[col]].copy()\n",
    "        temp_df['DataFrame'] = f'Cluster{i+1}'\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='DataFrame', y=col, data=combined_df)\n",
    "    plt.title(f'Boxplot of {col} across different DataFrames')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08921318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = ['Low', 'High']  \n",
    "columns = c_train_data[0].columns\n",
    "means_df = pd.DataFrame(index=columns, columns=df_names)\n",
    "\n",
    "for col in columns:\n",
    "    for name, df in zip(df_names, c_train_data):\n",
    "        means_df.loc[col, name] = df[col].mean()\n",
    "\n",
    "print(means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55212487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#High cluster has a total of 785 and a 2.17% percentage to experience wealth shock\n",
    "\n",
    "#Medium cluster has a total of 27466 and a 1.11% percentage to experience wealth shock\n",
    "\n",
    "#Low cluster has a total of 6993 and a 0.46% percentage to experience wealth shock\n",
    "\n",
    "#Age are very similar across all three clsuters\n",
    "#High cluster experience significantly more drastic health declines and hospitalizations than medium cluster, the same applies to medium and low clusters\n",
    "#Low cluster has none of the specified diseases\n",
    "#High cluster has cancer rate of 100%\n",
    "#Home care, Cancer and HBP are the most significant factors differentiating high, mdeium and low clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_data[0].to_csv('Low_train.csv', index=False)\n",
    "c_train_data[1].to_csv('High_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from skbio import DistanceMatrix\n",
    "from skbio.stats.distance import permanova\n",
    "from skbio.stats.distance import anosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d075c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_test_data = []\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    c_test_data.append(Shock_test_clusters[Shock_test_clusters[\"cluster\"] == i].drop(\"cluster\",axis=1))\n",
    "\n",
    "for i in range(len(c_test_data)):\n",
    "    print(\"CLUSTER {:d}\".format(i))\n",
    "    display(c_test_data[i])\n",
    "    print(\"-\" * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8ddc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_names = ['Low', 'High']  \n",
    "columns = c_test_data[0].columns\n",
    "means_df = pd.DataFrame(index=columns, columns=df_names)\n",
    "\n",
    "for col in columns:\n",
    "    for name, df in zip(df_names, c_test_data):\n",
    "        means_df.loc[col, name] = df[col].mean()\n",
    "\n",
    "print(means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e269815",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test_data[0].to_csv('Low_test.csv', index=False)\n",
    "c_test_data[1].to_csv('High_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ea3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "if len(X_train_norm) > sample_size:\n",
    "    indices = np.random.choice(len(X_train_norm), size=sample_size, replace=False)\n",
    "    X_train_sampled = X_train_norm[indices]\n",
    "else:\n",
    "    X_train_sampled = X_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_sampled = DistanceMatrix(distance_matrix(X_train_sampled, X_train_sampled))\n",
    "clusters_sampled = clusters[indices]\n",
    "result_anosim = anosim(dm_sampled, clusters_sampled)\n",
    "print(result_anosim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39154839",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_permanova = permanova(dm_sampled, clusters_sampled)\n",
    "print(result_permanova)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
